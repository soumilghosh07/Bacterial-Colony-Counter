{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet model for Bacterial Colony Count Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, strides=1, activation='relu'):\n",
    "    y = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation(activation)(y)\n",
    "    \n",
    "    y = layers.Conv2D(filters, kernel_size, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    \n",
    "    # Shortcut connection\n",
    "    if strides != 1 or x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, 1, strides=strides)(x)\n",
    "    return layers.add([x, y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    num_res_blocks = [2, 2, 2, 2]  # Number of residual blocks in each stage\n",
    "    filters = 64\n",
    "    for i, num_blocks in enumerate(num_res_blocks):\n",
    "        strides = 1 if i == 0 else 2\n",
    "        x = residual_block(x, filters, strides=strides)\n",
    "        for _ in range(num_blocks - 1):\n",
    "            x = residual_block(x, filters)\n",
    "        filters *= 2\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining input shape and number of classes\n",
    "input_shape = (180, 240, 1)\n",
    "num_classes = 1  # Colony count is a regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(180, 240)):\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    img = img.resize(target_size)\n",
    "    \n",
    "    # Convert image to numpy array and normalize pixel values to the range [0,1]\n",
    "    img_array = np.array(img) / 255.0  \n",
    "    \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "train_image_paths = [\n",
    "    \"frame_00_delay-0.1s.png\",\n",
    "    \"frame_01_delay-0.1s.png\",\n",
    "    \"frame_02_delay-0.1s.png\",\n",
    "    \"frame_03_delay-0.1s.png\",\n",
    "    \"frame_04_delay-0.1s.png\",\n",
    "    \"frame_05_delay-0.1s.png\",\n",
    "    \"frame_06_delay-0.1s.png\",\n",
    "    \"frame_07_delay-0.1s.png\",\n",
    "    \"frame_08_delay-0.1s.png\",\n",
    "    \"frame_09_delay-0.1s.png\",\n",
    "    \"frame_10_delay-0.1s.png\",\n",
    "    \"frame_11_delay-0.1s.png\",\n",
    "    \"frame_12_delay-0.1s.png\",\n",
    "    \"frame_13_delay-0.1s.png\",\n",
    "    \"frame_14_delay-0.1s.png\",\n",
    "    \"frame_15_delay-0.1s.png\",\n",
    "    \"frame_16_delay-0.1s.png\",\n",
    "    \"frame_17_delay-0.1s.png\",\n",
    "    \"frame_18_delay-0.1s.png\",\n",
    "    \"frame_19_delay-0.1s.png\",\n",
    "    \"frame_20_delay-0.1s.png\",\n",
    "    \"frame_21_delay-0.1s.png\",\n",
    "    \"frame_22_delay-0.1s.png\",\n",
    "    \"frame_23_delay-0.1s.png\",\n",
    "    \"frame_24_delay-0.1s.png\",\n",
    "    \"frame_25_delay-0.1s.png\"\n",
    "]\n",
    "train_images = []\n",
    "train_counts= [3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,6,7,7,7,8,8,8,8,8,8]\n",
    "\n",
    "for image_path in train_image_paths:\n",
    "    img = load_and_preprocess_image(image_path)  # Loading and preprocessing of image\n",
    "    train_images.append(img)\n",
    "\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "train_counts = np.array(train_counts)\n",
    "train_images = train_images.reshape(-1, 180, 240, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_paths = [\n",
    "    \"frame_26_delay-0.1s.png\",\n",
    "    \"frame_27_delay-0.1s.png\",\n",
    "    \"frame_28_delay-0.1s.png\",\n",
    "    \"frame_29_delay-0.1s.png\",\n",
    "    \"frame_30_delay-0.1s.png\"\n",
    "]\n",
    "val_images = []\n",
    "val_counts= [8,9,9,13,13]\n",
    "for image_path in val_image_paths:\n",
    "    img = load_and_preprocess_image(image_path)  # Loading and preprocessing image\n",
    "    val_images.append(img)\n",
    "val_counts = np.array(val_counts)\n",
    "val_images = np.array(val_images)\n",
    "val_images = val_images.reshape(-1, 180, 240, 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_paths = [\n",
    "    \"frame_31_delay-0.1s.png\",\n",
    "    \"frame_32_delay-0.1s.png\",\n",
    "    \"frame_33_delay-0.1s.png\",\n",
    "    \"frame_34_delay-0.1s.png\",\n",
    "    \"frame_35_delay-0.1s.png\",\n",
    "    \"frame_36_delay-0.1s.png\",\n",
    "    \"frame_37_delay-0.1s.png\",\n",
    "    \"frame_38_delay-0.1s.png\",\n",
    "    \"frame_39_delay-0.1s.png\"\n",
    "]\n",
    "test_images = []\n",
    "test_counts= [13,15,16,16,16,16,16,17,17]\n",
    "for image_path in test_image_paths:\n",
    "    img = load_and_preprocess_image(image_path)  # Loading and preprocessing image\n",
    "    test_images.append(img)\n",
    "test_counts = np.array(test_counts)\n",
    "test_images = np.array(test_images)\n",
    "test_images = test_images.reshape(-1, 180, 240, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 5s 840ms/step - loss: 7.0728 - mae: 1.8859 - val_loss: 7334.7397 - val_mae: 85.6205\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 798ms/step - loss: 3.3763 - mae: 1.2802 - val_loss: 5601.6299 - val_mae: 74.6014\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 804ms/step - loss: 4.3039 - mae: 1.5135 - val_loss: 10691.0996 - val_mae: 103.1902\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 801ms/step - loss: 2.9429 - mae: 1.3383 - val_loss: 1419.5129 - val_mae: 37.2669\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 783ms/step - loss: 1.4080 - mae: 1.0165 - val_loss: 4502.8008 - val_mae: 66.9884\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 786ms/step - loss: 1.8795 - mae: 1.1910 - val_loss: 19108.5879 - val_mae: 138.2069\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 783ms/step - loss: 2.1633 - mae: 1.2620 - val_loss: 28319.7227 - val_mae: 168.2718\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 784ms/step - loss: 0.9797 - mae: 0.7495 - val_loss: 30849.8906 - val_mae: 175.6324\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 748ms/step - loss: 0.4719 - mae: 0.5672 - val_loss: 29527.7617 - val_mae: 171.8284\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 763ms/step - loss: 0.6907 - mae: 0.6650 - val_loss: 26294.5996 - val_mae: 162.1465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_images, train_counts, epochs=10, batch_size=13, validation_data=(val_images, val_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step - loss: 30226.5273 - mae: 173.8319\n",
      "Test Loss: 30226.52734375, Test MAE: 173.83193969726562\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(test_images, test_counts)\n",
    "print(f'Test Loss: {test_loss}, Test MAE: {test_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 424ms/step\n",
      "Predicted Colony Count: [-159.68564]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load image from file path\n",
    "trial = Image.open(\"frame_38_delay-0.1s.png\")\n",
    "\n",
    "# Resize image to target size\n",
    "trial = trial.resize((180, 240))\n",
    "\n",
    "# Convert image to numpy array and normalize pixel values\n",
    "trial_array = np.array(trial) / 255.0  # Normalize pixel values to range [0, 1]\n",
    "trial_array = trial_array.reshape(180, 240, 1)\n",
    "predicted_count = model.predict(np.expand_dims(trial_array, axis=0))[0]\n",
    "\n",
    "print(\"Predicted Colony Count:\", predicted_count)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
